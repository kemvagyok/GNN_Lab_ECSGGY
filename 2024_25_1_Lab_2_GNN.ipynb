{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fL3d0GLtbkoW",
        "XVlO7h4OcvdI",
        "ZZhVO-WSdPys",
        "iUJzhbdCdSjQ",
        "G7t2n8qOJy8L",
        "dxwhExaMY6Px",
        "re_gBUEDeEnE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neutral Network\n",
        "- **2024/25/1**: Önálló laboratórium 2\n",
        "- Sági Benedek\n",
        "- **Konzulens**: Unyi Dániel\n",
        "- **Projekt és a célja**: A gráf neurális hálózatban a döntésekhez készítünk egy/több magyarázhatósági algoritmust, mely elmondja, hogy egy adott modell miért hozott ilyen döntést.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IwFzp4EkZq9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch\n",
        "!pip install torch==2.4.0"
      ],
      "metadata": {
        "id": "k6UZIdCr-FpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da528925-7414-4b04-ba9d-faf7f614da53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.4.0\n",
            "Uninstalling torch-2.4.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.4.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torch-2.4.0\n",
            "Collecting torch==2.4.0\n",
            "  Using cached torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Using cached torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html"
      ],
      "metadata": {
        "id": "JbEz1KCDkfN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a83d32f-3757-46be-fcc8-dc2f4e842d3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt24cpu)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt24cpu)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt24cpu)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt24cpu)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt24cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torch_geometric\n",
        "\n",
        "from torch_geometric import datasets\n",
        "\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from torch_geometric.loader import LinkLoader\n",
        "\n",
        "import torch_sparse\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hmWbUZFlbw7g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "5rFYftlmeD19"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lépések:\n",
        "\n",
        "##1.fázis\n",
        "---\n",
        "1. Adatok letöltése, előkészítése\n",
        "Mivel a pytorch geometrich könyvtárnak van az az API-ja, amivel le lehet tölteni a kiválasztott adathalmazokat.\n",
        "2. Adatok áttekintése\n",
        "3. Modellek készítése különböző célokra\n",
        "  * Csúcs szintű osztályozás\n",
        "  * Gráf szintű osztályozás\n",
        "  * Élprédikció\n",
        "\n",
        "4. Eredmények elemzése\n",
        "---\n",
        "Nem ajánlott egyszerre összeset indítani, mivel akkor sokáig fog tartani, főleg a negyediknél.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JO4IcslyahM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Adatok letöltése"
      ],
      "metadata": {
        "id": "fL3d0GLtbkoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WikipediaNetwork\n",
        "dataset_WikipediaNetwork = datasets.WikipediaNetwork(root='data/WikipediaNetwork', name = 'chameleon')\n",
        "#Amazon\n",
        "dataset_Amazon = datasets.Amazon(root='data/Amazon', name = 'Computers')\n",
        "#FacebookPagePage\n",
        "dataset_FacebookPagePage = datasets.FacebookPagePage(root='data/FacebookPagePage')"
      ],
      "metadata": {
        "id": "G10hTqL6bhw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9331b4c-fb58-4911-f86e-b914d87a06e8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Adatok áttekintése"
      ],
      "metadata": {
        "id": "XVlO7h4OcvdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_info(dataset):\n",
        "  print(f'Dataset: {dataset}:')\n",
        "  print('======================')\n",
        "  print(f'Number of graphs: {len(dataset)}')\n",
        "  print(f'Number of features: {dataset.num_features}')\n",
        "  print(f'Number of classes: {dataset.num_classes}')\n",
        "  data = dataset[0]  # Get the first graph object.\n",
        "  print(data)\n",
        "  print(f'Number of nodes: {data.num_nodes}')\n",
        "  print(f'Number of edges: {data.num_edges}')\n",
        "  print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "  print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "  print(f'Has self-loops: {data.has_self_loops()}')\n",
        "  print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "id": "-AuXavjEgrrc"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_info(dataset_WikipediaNetwork)\n",
        "dataset_info(dataset_Amazon)\n",
        "dataset_info(dataset_FacebookPagePage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CExyjpij7Xh",
        "outputId": "3bed11ba-0687-4735-8e5b-b253a453213c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: WikipediaNetwork():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 2325\n",
            "Number of classes: 5\n",
            "Data(x=[2277, 2325], edge_index=[2, 36101], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10])\n",
            "Number of nodes: 2277\n",
            "Number of edges: 36101\n",
            "Average node degree: 15.85\n",
            "Has isolated nodes: False\n",
            "Has self-loops: True\n",
            "Is undirected: False\n",
            "Dataset: AmazonComputers():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 767\n",
            "Number of classes: 10\n",
            "Data(x=[13752, 767], edge_index=[2, 491722], y=[13752])\n",
            "Number of nodes: 13752\n",
            "Number of edges: 491722\n",
            "Average node degree: 35.76\n",
            "Has isolated nodes: True\n",
            "Has self-loops: False\n",
            "Is undirected: True\n",
            "Dataset: FacebookPagePage():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 128\n",
            "Number of classes: 4\n",
            "Data(x=[22470, 128], edge_index=[2, 342004], y=[22470])\n",
            "Number of nodes: 22470\n",
            "Number of edges: 342004\n",
            "Average node degree: 15.22\n",
            "Has isolated nodes: False\n",
            "Has self-loops: True\n",
            "Is undirected: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Következetés\n",
        "*   Reddit:\n",
        "Ebben az adathalmazban nincs egyéb érdekesség, azaz indirekt, nincs DAG, és nincsenek izolált pontok. Csak egy gráf.\n",
        "*   UPFD:\n",
        "Ám ebben vannak izolált pontok, sőt több gráf is van.\n",
        "*   Airports:\n",
        "Itt viszont van DAG.\n",
        "\n"
      ],
      "metadata": {
        "id": "gn8ATmK8DDMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for graph_n in range(62):\n",
        "  data = dataset_UPFD[graph_n]  # Get the first graph object.\n",
        "  print(graph_n)\n",
        "  print(data)\n",
        "  print(f'Number of nodes: {data.num_nodes}')\n",
        "  print(f'Number of edges: {data.num_edges}')\n",
        "  print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "  print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "  print(f'Has self-loops: {data.has_self_loops()}')\n",
        "  print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "id": "9CNyxRM_WCue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Modellek készítése"
      ],
      "metadata": {
        "id": "ZZhVO-WSdPys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Csúcs szintű osztályozás\n",
        "- Gráf konvolucios hálózat\n",
        "Innen vettem ezt az alapvető kódot: https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=fmXWs1dKIzD8\n",
        "- Ez alapján bovitettem: https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers\n",
        "- A működését ennek segítségével értelmeztem: https://tkipf.github.io/graph-convolutional-networks/"
      ],
      "metadata": {
        "id": "iUJzhbdCdSjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
        "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.conv4 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def  forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "i9OR3CMJ_-zg"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Élprédikáció"
      ],
      "metadata": {
        "id": "G7t2n8qOJy8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_index):\n",
        "        src, dst = edge_index\n",
        "        z_src, z_dst = z[src], z[dst]\n",
        "        return torch.sigmoid(self.fc(torch.cat([z_src, z_dst], dim=1)))\n",
        "\n",
        "    def forward(self, data):\n",
        "        z = self.encode(data.x, data.edge_index)\n",
        "        return self.decode(z, data.edge_index)"
      ],
      "metadata": {
        "id": "V-nVsx8HJ2Yv"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gráfszintu osztalyozas"
      ],
      "metadata": {
        "id": "dxwhExaMY6Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNGraphClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCNGraphClassifier, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)  # Gráf szintű pooling\n",
        "        return F.log_softmax(self.fc(x), dim=1)\n"
      ],
      "metadata": {
        "id": "DsibwYLaeLzf"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Eredmények és elemzése"
      ],
      "metadata": {
        "id": "re_gBUEDeEnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_neighbors = [10,10]\n",
        "lr = 1e-3\n",
        "hidden_dim = 64"
      ],
      "metadata": {
        "id": "4QAj_dZcmKVq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creatingMask(dataset, train_ratio=0.8, test_ratio = 0.2):\n",
        "  data = dataset[0]\n",
        "  num_nodes = data.num_nodes\n",
        "  perm = torch.randperm(data.num_nodes)\n",
        "  train_mask = perm[:int(data.num_nodes * train_ratio)]\n",
        "  test_mask = perm[int(data.num_nodes * test_ratio):]\n",
        "  data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "  data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "  data.train_mask[train_mask] = True\n",
        "  data.test_mask[test_mask] = True\n",
        "  return data"
      ],
      "metadata": {
        "id": "jjd92TS2Wtzu"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Csúcs szintű osztályozás"
      ],
      "metadata": {
        "id": "8KftBk7veySf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_train_model(train_loader, test_loader, optimizer, model, device):\n",
        "  def train():\n",
        "      count=0\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch in train_loader:\n",
        "          batch = batch.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          out = model(batch.x, batch.edge_index)\n",
        "          criterion = CrossEntropyLoss()\n",
        "          loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "      return total_loss / len(train_loader)\n",
        "  def test():\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total = 0  # Összes tesztadat száma\n",
        "      for batch in test_loader:\n",
        "          batch = batch.to(device)\n",
        "          out = model(batch.x, batch.edge_index)\n",
        "          pred = out.max(dim=1)[1]\n",
        "          correct += pred.eq(batch.y).sum().item() # Kiszámolja, hogy abbol mennyi el lett találva az eq metódus segítségével\n",
        "          total += batch.y.size(0)  # Összes minta száma\n",
        "      return correct / total\n",
        "  for epoch in range(10):\n",
        "    loss = train()\n",
        "    acc = test()\n",
        "    #Elemzés\n",
        "    print(f'Epoch {epoch}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "id": "N6K4LuslVHxO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nodeMainModel(data, num_classes, num_features):\n",
        "  train_loader = NeighborLoader(data, num_neighbors=num_neighbors , batch_size=batch_size, input_nodes=data.train_mask)\n",
        "  test_loader = NeighborLoader(data, num_neighbors=num_neighbors , batch_size=batch_size, input_nodes=data.test_mask)\n",
        "  model = GCN(input_dim=num_features, hidden_dim=hidden_dim, output_dim=num_classes).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "  node_train_model(train_loader, test_loader, optimizer, model, device)"
      ],
      "metadata": {
        "id": "K6R3eeglZBqL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_WikipediaNetwork[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP0fKF1veoZi",
        "outputId": "81b1430f-6f5f-4760-ed7a-6ed18a254115"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2277, 2325], edge_index=[2, 36101], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with masks\n",
        "for dataset in [dataset_WikipediaNetwork]:\n",
        "  print(dataset)\n",
        "  nodeMainModel(dataset[0],dataset.num_classes, dataset.num_features)\n",
        "#without masks\n",
        "for dataset in [dataset_Amazon,dataset_FacebookPagePage]:\n",
        "  print(dataset)\n",
        "  nodeMainModel(creatingMask(dataset), dataset.num_classes, dataset.num_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "VM7mRdhzW23_",
        "outputId": "c679d4b9-250d-4ea8-df30-3e29d691df73"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WikipediaNetwork()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-97c0315f3093>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset_WikipediaNetwork\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mnodeMainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#without masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset_Amazon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_FacebookPagePage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-64cb610f5b18>\u001b[0m in \u001b[0;36mnodeMainModel\u001b[0;34m(data, num_classes, num_features)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnodeMainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeighborLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_neighbors\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeighborLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_neighbors\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/neighbor_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, num_neighbors, input_nodes, input_time, replace, subgraph_type, disjoint, temporal_strategy, time_attr, weight_attr, transform, transform_sampler_output, is_sorted, filter_per_worker, neighbor_sampler, directed, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mnode_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbor_sampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/node_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, node_sampler, input_nodes, input_time, transform, transform_sampler_output, filter_per_worker, custom_cls, input_id, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# Get node type (or `None` for homogeneous graphs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         input_type, input_nodes, input_id = get_input_nodes(\n\u001b[0m\u001b[1;32m    121\u001b[0m             data, input_nodes, input_id)\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/utils.py\u001b[0m in \u001b[0;36mget_input_nodes\u001b[0;34m(data, input_nodes, input_id)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_nodes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mto_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/utils.py\u001b[0m in \u001b[0;36mto_index\u001b[0;34m(nodes, input_id)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Élprédikáció"
      ],
      "metadata": {
        "id": "Q3K5xViRWE72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_train_model(train_loader, test_loader, optimizer, model, device):\n",
        "    def train():\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Kódolás\n",
        "            z = model.encode(batch.x, batch.edge_index)\n",
        "\n",
        "            # Pozitív élek dekódolása\n",
        "            pos_pred = model.decode(z, batch.edge_index)\n",
        "\n",
        "            # Negatív minták generálása\n",
        "            neg_edge_index = negative_sampling(\n",
        "                edge_index=batch.edge_index, num_nodes=batch.x.size(0), num_neg_samples=batch.edge_index.size(1)\n",
        "            )\n",
        "\n",
        "            # Negatív élek dekódolása\n",
        "            neg_pred = model.decode(z, neg_edge_index)\n",
        "\n",
        "            # Loss számítása: Pozitív és negatív minták összehasonlítása\n",
        "            pos_loss = F.binary_cross_entropy(pos_pred.squeeze(), torch.ones(pos_pred.size(0)).to(device))\n",
        "            neg_loss = F.binary_cross_entropy(neg_pred.squeeze(), torch.zeros(neg_pred.size(0)).to(device))\n",
        "\n",
        "            # Teljes veszteség\n",
        "            loss = pos_loss + neg_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(train_loader)\n",
        "\n",
        "    def test():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0  # Összes tesztadat száma\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                batch = batch.to(device)\n",
        "\n",
        "                # Kódolás és predikció\n",
        "                z = model.encode(batch.x, batch.edge_index)\n",
        "\n",
        "                # Pozitív élek predikciója\n",
        "                pos_pred = model.decode(z, batch.edge_index)\n",
        "                '''\n",
        "                # Negatív élek mintavételezése (azaz BSZ2 szempontjából komplementere)\n",
        "                neg_edge_index = negative_sampling(\n",
        "                    edge_index=batch.edge_index, num_nodes=batch.x.size(0), num_neg_samples=batch.edge_index.size(1)\n",
        "                )\n",
        "                neg_pred = model.decode(z, neg_edge_index)\n",
        "                '''\n",
        "                # Predikciók összehasonlítása\n",
        "                pos_correct = (pos_pred > 0.5).sum().item()\n",
        "                #neg_correct = (neg_pred < 0.5).sum().item()\n",
        "\n",
        "                #correct += pos_correct + neg_correct\n",
        "                correct += pos_correct\n",
        "                #total += pos_pred.size(0) + neg_pred.size(0)\n",
        "                total += pos_pred.size(0)\n",
        "        return correct / total\n",
        "\n",
        "    for epoch in range(10):\n",
        "        loss = train()\n",
        "        acc = test()\n",
        "        # Elemzés\n",
        "        print(f'Epoch {epoch}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')\n"
      ],
      "metadata": {
        "id": "6GeRuvt_MiuP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edgeMainModel(data,  num_classes, num_features):\n",
        "\n",
        "  transform = RandomLinkSplit(is_undirected=True)\n",
        "  train_data, val_data, test_data = transform(data)\n",
        "\n",
        "  train_loader = LinkNeighborLoader(\n",
        "      train_data,\n",
        "      num_neighbors=num_neighbors,\n",
        "      batch_size=batch_size,\n",
        "      edge_label_index=train_data.edge_index,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  test_loader = LinkNeighborLoader(\n",
        "      test_data,\n",
        "      num_neighbors=num_neighbors,\n",
        "      batch_size=batch_size,\n",
        "      edge_label_index=test_data.edge_index,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  model = LinkPredictor(num_node_features, hidden_dim=hidden_dim).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  edge_train_model(train_loader, test_loader, optimizer, model, device)"
      ],
      "metadata": {
        "id": "-B_1SLG9DKix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with masks\n",
        "for dataset in [dataset_Reddit]:\n",
        "  print(dataset)\n",
        "  edgeMainModel(dataset[0])\n",
        "#without masks\n",
        "for dataset in [dataset_FacebookPagePage]:\n",
        "  print(dataset)\n",
        "  edgeMainModel(creatingMask(dataset[0]))"
      ],
      "metadata": {
        "id": "5WxY8QJ3Zd-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gráfszintű osztályozás"
      ],
      "metadata": {
        "id": "gMf8vvho35bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def datasetWithMask(dataset, train_ratio, test_ratio, model):\n",
        "  data = dataset[0]\n",
        "\n",
        "model = GCNGraphClassifier(data.num_edge_features, hidden_dim, data.num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "9NOQP4rh34ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.fázis\n",
        "--------\n",
        "Folytatás\n",
        "--------\n"
      ],
      "metadata": {
        "id": "VUxv5CwDaffr"
      }
    }
  ]
}