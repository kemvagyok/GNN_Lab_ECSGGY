{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwFzp4EkZq9V"
      },
      "source": [
        "# Graph Neutral Network\n",
        "- **2024/25/1**: Önálló laboratórium 2\n",
        "- Sági Benedek\n",
        "- **Konzulens**: Unyi Dániel\n",
        "- **Projekt és a célja**: A gráf neurális hálózatban a döntésekhez készítünk egy/több magyarázhatósági algoritmust, mely elmondja, hogy egy adott modell miért hozott ilyen döntést.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6UZIdCr-FpH",
        "outputId": "7a789cd7-0559-49f8-cc8f-ca66d0bece0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.0+cu121\n",
            "Uninstalling torch-2.5.0+cu121:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchfrtrace\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.5.0+cu121.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torch-2.5.0+cu121\n",
            "Collecting torch==2.4.0\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch\n",
        "!pip install torch==2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbEz1KCDkfN0",
        "outputId": "bdffc7cc-0a1b-461d-f692-31aa695cd0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcpu/pyg_lib-0.4.0%2Bpt24cpu-cp310-cp310-linux_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcpu/torch_scatter-2.1.2%2Bpt24cpu-cp310-cp310-linux_x86_64.whl (541 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.0/541.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcpu/torch_sparse-0.6.18%2Bpt24cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcpu/torch_cluster-1.6.3%2Bpt24cpu-cp310-cp310-linux_x86_64.whl (787 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m787.5/787.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt24cpu-cp310-cp310-linux_x86_64.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt24cpu torch_cluster-1.6.3+pt24cpu torch_scatter-2.1.2+pt24cpu torch_sparse-0.6.18+pt24cpu torch_spline_conv-1.2.2+pt24cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "!pip install torch_geometric\n",
        "if torch.cuda.is_available():\n",
        "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "else:\n",
        "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "hmWbUZFlbw7g"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "import torch_geometric\n",
        "\n",
        "from torch_geometric import datasets\n",
        "\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, global_mean_pool,BatchNorm\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from torch_geometric.loader import LinkLoader\n",
        "\n",
        "import torch_sparse\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import wandb\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5rFYftlmeD19"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO4IcslyahM9"
      },
      "source": [
        "Lépések:\n",
        "\n",
        "##1.fázis\n",
        "---\n",
        "1. Adatok letöltése, előkészítése\n",
        "Mivel a pytorch geometrich könyvtárnak van az az API-ja, amivel le lehet tölteni a kiválasztott adathalmazokat.\n",
        "2. Adatok áttekintése\n",
        "3. Modellek készítése különböző célokra\n",
        "  * Csúcs szintű osztályozás\n",
        "  * Gráf szintű osztályozás\n",
        "  * Élprédikció\n",
        "\n",
        "4. Eredmények elemzése\n",
        "---\n",
        "Nem ajánlott egyszerre összeset indítani, mivel akkor sokáig fog tartani, főleg a negyediknél.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL3d0GLtbkoW"
      },
      "source": [
        "### 1. Adatok letöltése"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G10hTqL6bhw8",
        "outputId": "200c11bf-12ae-4d29-c5f7-6e5f3d4fefb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/new_data/chameleon/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/new_data/chameleon/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_9.npz\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://graphmining.ai/datasets/ptg/facebook.npz\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://data.pyg.org/datasets/benchmarking-gnns/MNIST_v2.zip\n",
            "Extracting data/GNNBenchmarkDataset/MNIST/raw/MNIST_v2.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#WikipediaNetwork\n",
        "dataset_WikipediaNetwork = datasets.WikipediaNetwork(root='data/WikipediaNetwork', name = 'chameleon')\n",
        "#Amazon\n",
        "dataset_Amazon = datasets.Amazon(root='data/Amazon', name = 'Computers')\n",
        "#FacebookPagePage\n",
        "dataset_FacebookPagePage = datasets.FacebookPagePage(root='data/FacebookPagePage')\n",
        "#ZINC (https://pytorch-geometric.readthedocs.io/en/2.5.2/generated/torch_geometric.datasets.ZINC.html#torch_geometric.datasets.ZINC)\n",
        "dataset_ENZYMES = datasets.TUDataset(root='data/TUDataset', name ='ENZYMES')\n",
        "dataset_MNIST = datasets.GNNBenchmarkDataset(root='data/GNNBenchmarkDataset', name='MNIST')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVlO7h4OcvdI"
      },
      "source": [
        "### 2. Adatok áttekintése"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AuXavjEgrrc"
      },
      "outputs": [],
      "source": [
        "def dataset_info(dataset):\n",
        "  print(f'Dataset: {dataset}:')\n",
        "  print('======================')\n",
        "  print(f'Number of graphs: {len(dataset)}')\n",
        "  print(f'Number of features: {dataset.num_features}')\n",
        "  print(f'Number of classes: {dataset.num_classes}')\n",
        "  data = dataset[0]  # Get the first graph object.\n",
        "  print(data)\n",
        "  print(f'Number of nodes: {data.num_nodes}')\n",
        "  print(f'Number of edges: {data.num_edges}')\n",
        "  print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "  print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "  print(f'Has self-loops: {data.has_self_loops()}')\n",
        "  print(f'Is undirected: {data.is_undirected()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CExyjpij7Xh",
        "outputId": "3bed11ba-0687-4735-8e5b-b253a453213c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: WikipediaNetwork():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 2325\n",
            "Number of classes: 5\n",
            "Data(x=[2277, 2325], edge_index=[2, 36101], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10])\n",
            "Number of nodes: 2277\n",
            "Number of edges: 36101\n",
            "Average node degree: 15.85\n",
            "Has isolated nodes: False\n",
            "Has self-loops: True\n",
            "Is undirected: False\n",
            "Dataset: AmazonComputers():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 767\n",
            "Number of classes: 10\n",
            "Data(x=[13752, 767], edge_index=[2, 491722], y=[13752])\n",
            "Number of nodes: 13752\n",
            "Number of edges: 491722\n",
            "Average node degree: 35.76\n",
            "Has isolated nodes: True\n",
            "Has self-loops: False\n",
            "Is undirected: True\n",
            "Dataset: FacebookPagePage():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 128\n",
            "Number of classes: 4\n",
            "Data(x=[22470, 128], edge_index=[2, 342004], y=[22470])\n",
            "Number of nodes: 22470\n",
            "Number of edges: 342004\n",
            "Average node degree: 15.22\n",
            "Has isolated nodes: False\n",
            "Has self-loops: True\n",
            "Is undirected: True\n"
          ]
        }
      ],
      "source": [
        "dataset_info(dataset_WikipediaNetwork)\n",
        "dataset_info(dataset_Amazon)\n",
        "dataset_info(dataset_FacebookPagePage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZhVO-WSdPys"
      },
      "source": [
        "### 3. Modellek készítése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUJzhbdCdSjQ"
      },
      "source": [
        "#### Csúcs szintű osztályozás\n",
        "- Gráf konvolucios hálózat\n",
        "Innen vettem ezt az alapvető kódot: https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=fmXWs1dKIzD8\n",
        "- Ez alapján bovitettem: https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers\n",
        "- A működését ennek segítségével értelmeztem: https://tkipf.github.io/graph-convolutional-networks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9OR3CMJ_-zg"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
        "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.conv4 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def  forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7t2n8qOJy8L"
      },
      "source": [
        "#### Élprédikáció"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-nVsx8HJ2Yv"
      },
      "outputs": [],
      "source": [
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_index):\n",
        "        src, dst = edge_index\n",
        "        z_src, z_dst = z[src], z[dst]\n",
        "        return torch.sigmoid(self.fc(torch.cat([z_src, z_dst], dim=1)))\n",
        "\n",
        "    def forward(self, data):\n",
        "        z = self.encode(data.x, data.edge_index)\n",
        "        return self.decode(z, data.edge_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxwhExaMY6Px"
      },
      "source": [
        "#### Gráfszintu osztalyozas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "DsibwYLaeLzf"
      },
      "outputs": [],
      "source": [
        "class GCNGraphClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCNGraphClassifier, self).__init__()\n",
        "        # Define convolution layers with both SAGE and GCN layers\n",
        "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
        "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.conv4 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "        # Batch normalization layers for stabilizing training\n",
        "        self.bn1 = BatchNorm(hidden_dim)\n",
        "        self.bn2 = BatchNorm(hidden_dim)\n",
        "        self.bn3 = BatchNorm(hidden_dim)\n",
        "        self.bn4 = BatchNorm(hidden_dim)\n",
        "\n",
        "        # Fully connected layer for classification\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # Forward pass with activation and batch normalization\n",
        "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
        "        x = F.relu(self.bn3(self.conv3(x, edge_index)))\n",
        "        x = F.relu(self.bn4(self.conv4(x, edge_index)))\n",
        "\n",
        "        # Global pooling\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        # Dropout and fully connected layer\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re_gBUEDeEnE"
      },
      "source": [
        "### 4. Eredmények és elemzése"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "4QAj_dZcmKVq"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "num_neighbors = [10,10]\n",
        "lr = 2e-3\n",
        "hidden_dim = 64\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jjd92TS2Wtzu"
      },
      "outputs": [],
      "source": [
        "def creatingMask(dataset, train_ratio=0.8, test_ratio = 0.2):\n",
        "  data = dataset[0]\n",
        "  num_nodes = data.num_nodes\n",
        "  perm = torch.randperm(data.num_nodes)\n",
        "  train_mask = perm[:int(data.num_nodes * train_ratio)]\n",
        "  test_mask = perm[int(data.num_nodes * test_ratio):]\n",
        "  data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "  data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "  data.train_mask[train_mask] = True\n",
        "  data.test_mask[test_mask] = True\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KftBk7veySf"
      },
      "source": [
        "#### Csúcs szintű osztályozás"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6K4LuslVHxO"
      },
      "outputs": [],
      "source": [
        "def node_train_model(train_loader, test_loader, optimizer, model, device):\n",
        "  def train():\n",
        "      count=0\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch in train_loader:\n",
        "          batch = batch.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          out = model(batch.x, batch.edge_index)\n",
        "          criterion = CrossEntropyLoss()\n",
        "          loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "      return total_loss / len(train_loader)\n",
        "  def test():\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total = 0  # Összes tesztadat száma\n",
        "      for batch in test_loader:\n",
        "          batch = batch.to(device)\n",
        "          out = model(batch.x, batch.edge_index)\n",
        "          pred = out.max(dim=1)[1]\n",
        "          correct += pred.eq(batch.y).sum().item() # Kiszámolja, hogy abbol mennyi el lett találva az eq metódus segítségével\n",
        "          total += batch.y.size(0)  # Összes minta száma\n",
        "      return correct / total\n",
        "  for epoch in range(10):\n",
        "    loss = train()\n",
        "    acc = test()\n",
        "    #Elemzés\n",
        "    print(f'Epoch {epoch}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6R3eeglZBqL"
      },
      "outputs": [],
      "source": [
        "def nodeMainModel(data, num_classes, num_features):\n",
        "  print(num_neighbors)\n",
        "  print(batch_size)\n",
        "  print(data.train_mask.shape)\n",
        "\n",
        "  train_loader = NeighborLoader(data, num_neighbors=num_neighbors , batch_size=batch_size, input_nodes=data.train_mask)\n",
        "  test_loader = NeighborLoader(data, num_neighbors=num_neighbors , batch_size=batch_size, input_nodes=data.test_mask)\n",
        "\n",
        "  model = GCN(input_dim=num_features, hidden_dim=hidden_dim, output_dim=num_classes).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "  node_train_model(train_loader, test_loader, optimizer, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM7mRdhzW23_",
        "outputId": "4614d013-26c4-41bc-ddbc-0343f694440d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WikipediaNetwork()\n",
            "[10, 10]\n",
            "128\n",
            "torch.Size([2277])\n",
            "Epoch 0, Loss: 1.5994, Test Accuracy: 0.2999\n",
            "Epoch 1, Loss: 1.5477, Test Accuracy: 0.4459\n",
            "Epoch 2, Loss: 1.4754, Test Accuracy: 0.4548\n",
            "Epoch 3, Loss: 1.3654, Test Accuracy: 0.4802\n",
            "Epoch 4, Loss: 1.2352, Test Accuracy: 0.4785\n",
            "Epoch 5, Loss: 1.1273, Test Accuracy: 0.4874\n",
            "Epoch 6, Loss: 1.0315, Test Accuracy: 0.4619\n",
            "Epoch 7, Loss: 0.9806, Test Accuracy: 0.4625\n",
            "Epoch 8, Loss: 0.9118, Test Accuracy: 0.4597\n",
            "Epoch 9, Loss: 0.8523, Test Accuracy: 0.4691\n",
            "AmazonComputers()\n",
            "[10, 10]\n",
            "128\n",
            "torch.Size([13752])\n",
            "Epoch 0, Loss: 1.2907, Test Accuracy: 0.7183\n",
            "Epoch 1, Loss: 0.5991, Test Accuracy: 0.7791\n",
            "Epoch 2, Loss: 0.5053, Test Accuracy: 0.8025\n",
            "Epoch 3, Loss: 0.4599, Test Accuracy: 0.8088\n",
            "Epoch 4, Loss: 0.4256, Test Accuracy: 0.8025\n",
            "Epoch 5, Loss: 0.4079, Test Accuracy: 0.8059\n",
            "Epoch 6, Loss: 0.3870, Test Accuracy: 0.8034\n",
            "Epoch 7, Loss: 0.3759, Test Accuracy: 0.7980\n",
            "Epoch 8, Loss: 0.3650, Test Accuracy: 0.7946\n",
            "Epoch 9, Loss: 0.3450, Test Accuracy: 0.7883\n",
            "FacebookPagePage()\n",
            "[10, 10]\n",
            "128\n",
            "torch.Size([22470])\n",
            "Epoch 0, Loss: 0.4943, Test Accuracy: 0.7412\n",
            "Epoch 1, Loss: 0.2697, Test Accuracy: 0.7428\n",
            "Epoch 2, Loss: 0.2405, Test Accuracy: 0.7411\n",
            "Epoch 3, Loss: 0.2200, Test Accuracy: 0.7372\n",
            "Epoch 4, Loss: 0.2058, Test Accuracy: 0.7365\n",
            "Epoch 5, Loss: 0.1945, Test Accuracy: 0.7309\n",
            "Epoch 6, Loss: 0.1857, Test Accuracy: 0.7332\n",
            "Epoch 7, Loss: 0.1737, Test Accuracy: 0.7292\n",
            "Epoch 8, Loss: 0.1650, Test Accuracy: 0.7284\n",
            "Epoch 9, Loss: 0.1590, Test Accuracy: 0.7248\n"
          ]
        }
      ],
      "source": [
        "#with masks\n",
        "for dataset in [dataset_WikipediaNetwork]:\n",
        "  print(dataset)\n",
        "  data = dataset[0]\n",
        "  data.train_mask = data.train_mask[:,0]\n",
        "  data.test_mask = data.test_mask[:,0]\n",
        "  nodeMainModel(data,dataset.num_classes, dataset.num_features)\n",
        "#without masks\n",
        "for dataset in [dataset_Amazon,dataset_FacebookPagePage]:\n",
        "  print(dataset)\n",
        "  nodeMainModel(creatingMask(dataset), dataset.num_classes, dataset.num_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3K5xViRWE72"
      },
      "source": [
        "#### Élprédikáció"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GeRuvt_MiuP"
      },
      "outputs": [],
      "source": [
        "def edge_train_model(train_loader, test_loader, optimizer, model, device):\n",
        "    def train():\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Kódolás\n",
        "            z = model.encode(batch.x, batch.edge_index)\n",
        "\n",
        "            # Pozitív élek dekódolása\n",
        "            pos_pred = model.decode(z, batch.edge_index)\n",
        "\n",
        "            # Negatív minták generálása\n",
        "            neg_edge_index = negative_sampling(\n",
        "                edge_index=batch.edge_index, num_nodes=batch.x.size(0), num_neg_samples=batch.edge_index.size(1)\n",
        "            )\n",
        "\n",
        "            # Negatív élek dekódolása\n",
        "            neg_pred = model.decode(z, neg_edge_index)\n",
        "\n",
        "            # Loss számítása: Pozitív és negatív minták összehasonlítása\n",
        "            pos_loss = F.binary_cross_entropy(pos_pred.squeeze(), torch.ones(pos_pred.size(0)).to(device))\n",
        "            neg_loss = F.binary_cross_entropy(neg_pred.squeeze(), torch.zeros(neg_pred.size(0)).to(device))\n",
        "\n",
        "            # Teljes veszteség\n",
        "            loss = pos_loss + neg_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(train_loader)\n",
        "\n",
        "    def test():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0  # Összes tesztadat száma\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                batch = batch.to(device)\n",
        "\n",
        "                # Kódolás és predikció\n",
        "                z = model.encode(batch.x, batch.edge_index)\n",
        "\n",
        "                # Pozitív élek predikciója\n",
        "                pos_pred = model.decode(z, batch.edge_index)\n",
        "\n",
        "                # Negatív élek mintavételezése (azaz BSZ2 szempontjából komplementere)\n",
        "                neg_edge_index = negative_sampling(\n",
        "                    edge_index=batch.edge_index, num_nodes=batch.x.size(0), num_neg_samples=batch.edge_index.size(1)\n",
        "                )\n",
        "                neg_pred = model.decode(z, neg_edge_index)\n",
        "\n",
        "                # Predikciók összehasonlítása\n",
        "                pos_correct = (pos_pred > 0.5).sum().item()\n",
        "                neg_correct = (neg_pred < 0.5).sum().item()\n",
        "\n",
        "                correct += pos_correct + neg_correct\n",
        "                #correct += pos_correct\n",
        "                total += pos_pred.size(0) + neg_pred.size(0)\n",
        "                #total += pos_pred.size(0)\n",
        "        return correct / total\n",
        "\n",
        "    for epoch in range(10):\n",
        "        loss = train()\n",
        "        acc = test()\n",
        "        # Elemzés\n",
        "        print(f'Epoch {epoch}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B_1SLG9DKix"
      },
      "outputs": [],
      "source": [
        "def edgeMainModel(data,  num_classes, num_features, is_undirected):\n",
        "\n",
        "  transform = RandomLinkSplit(is_undirected=is_undirected)\n",
        "  train_data, val_data, test_data = transform(data)\n",
        "\n",
        "  train_loader = LinkNeighborLoader(\n",
        "      train_data,\n",
        "      num_neighbors=num_neighbors,\n",
        "      batch_size=batch_size,\n",
        "      edge_label_index=train_data.edge_index,\n",
        "      shuffle=True\n",
        "  )\n",
        "\n",
        "  test_loader = LinkNeighborLoader(\n",
        "      test_data,\n",
        "      num_neighbors=num_neighbors,\n",
        "      batch_size=batch_size,\n",
        "      edge_label_index=test_data.edge_index,\n",
        "      shuffle=False\n",
        "  )\n",
        "\n",
        "  model = LinkPredictor(num_features, hidden_dim=hidden_dim).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  edge_train_model(train_loader, test_loader, optimizer, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WxY8QJ3Zd-_",
        "outputId": "b60501a1-8431-4ebc-d460-baebec7533b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.1222, Test Accuracy: 0.7421\n",
            "Epoch 1, Loss: 0.9655, Test Accuracy: 0.6942\n",
            "Epoch 2, Loss: 0.9431, Test Accuracy: 0.7832\n",
            "Epoch 3, Loss: 0.9272, Test Accuracy: 0.7638\n",
            "Epoch 4, Loss: 0.9219, Test Accuracy: 0.7901\n",
            "Epoch 5, Loss: 0.9176, Test Accuracy: 0.7257\n",
            "Epoch 6, Loss: 0.9121, Test Accuracy: 0.7905\n",
            "Epoch 7, Loss: 0.9061, Test Accuracy: 0.8000\n",
            "Epoch 8, Loss: 0.9062, Test Accuracy: 0.7833\n",
            "Epoch 9, Loss: 0.9050, Test Accuracy: 0.7820\n",
            "AmazonComputers()\n",
            "Epoch 0, Loss: 0.7639, Test Accuracy: 0.8555\n",
            "Epoch 1, Loss: 0.7043, Test Accuracy: 0.8580\n",
            "Epoch 2, Loss: 0.6970, Test Accuracy: 0.8597\n",
            "Epoch 3, Loss: 0.6940, Test Accuracy: 0.8585\n",
            "Epoch 4, Loss: 0.6902, Test Accuracy: 0.8588\n",
            "Epoch 5, Loss: 0.6891, Test Accuracy: 0.8595\n",
            "Epoch 6, Loss: 0.6838, Test Accuracy: 0.8587\n",
            "Epoch 7, Loss: 0.6793, Test Accuracy: 0.8615\n",
            "Epoch 8, Loss: 0.6785, Test Accuracy: 0.8586\n",
            "Epoch 9, Loss: 0.6770, Test Accuracy: 0.8603\n",
            "FacebookPagePage()\n",
            "Epoch 0, Loss: 0.7785, Test Accuracy: 0.8543\n",
            "Epoch 1, Loss: 0.7075, Test Accuracy: 0.8548\n",
            "Epoch 2, Loss: 0.6966, Test Accuracy: 0.8558\n",
            "Epoch 3, Loss: 0.6921, Test Accuracy: 0.8567\n",
            "Epoch 4, Loss: 0.6899, Test Accuracy: 0.8570\n",
            "Epoch 5, Loss: 0.6883, Test Accuracy: 0.8570\n",
            "Epoch 6, Loss: 0.6869, Test Accuracy: 0.8561\n",
            "Epoch 7, Loss: 0.6863, Test Accuracy: 0.8567\n",
            "Epoch 8, Loss: 0.6857, Test Accuracy: 0.8576\n",
            "Epoch 9, Loss: 0.6850, Test Accuracy: 0.8571\n"
          ]
        }
      ],
      "source": [
        "#with masks\n",
        "for dataset in [dataset_WikipediaNetwork]:\n",
        "  data = dataset[0]\n",
        "  data.train_mask = data.train_mask[:,0]\n",
        "  data.test_mask = data.test_mask[:,0]\n",
        "  edgeMainModel(data, dataset.num_classes, dataset.num_features)\n",
        "#without masks\n",
        "for dataset in [dataset_Amazon, dataset_FacebookPagePage]:\n",
        "  print(dataset)\n",
        "  edgeMainModel(creatingMask(dataset),dataset.num_classes, dataset.num_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMf8vvho35bR"
      },
      "source": [
        "#### Gráfszintű osztályozás"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start a new wandb run to track this script\n",
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"GNN_project\",\n",
        "\n",
        "    # track hyperparameters and run metadata\n",
        "    config={\n",
        "    \"learning_rate\": lr,\n",
        "    \"architecture\": \"GNN\",\n",
        "    \"dataset\": \"dataset_ENZYMES\",\n",
        "    \"epochs\": 171,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "mGjIzshTCOc5",
        "outputId": "812ed172-02b5-47e6-a1c0-2fcc7f4bde16"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m0322sagibenedek\u001b[0m (\u001b[33m0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241101_220332-8gljqey3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project/runs/8gljqey3' target=\"_blank\">dazzling-victory-4</a></strong> to <a href='https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project' target=\"_blank\">https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project/runs/8gljqey3' target=\"_blank\">https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project/runs/8gljqey3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project/runs/8gljqey3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b60000e2cb0>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_train_model(train_loader, test_loader, optimizer, criterion, model, device):\n",
        "    def train():\n",
        "      loss = 0\n",
        "      model.train()\n",
        "      for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "          data = data.to(device)\n",
        "          out = model(data)  # Perform a single forward pass.\n",
        "          loss = criterion(out, data.y)  # Compute the loss.\n",
        "          loss.backward()  # Derive gradients.\n",
        "          optimizer.step()  # Update parameters based on gradients.\n",
        "          optimizer.zero_grad()  # Clear gradients.\n",
        "          loss += loss.item()\n",
        "      return loss / len(train_loader)\n",
        "    def test():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        for data in test_loader:  # Iterate in batches over the training/test dataset.\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "            correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
        "        return correct / len(test_loader.dataset)  # Derive ratio of correct predictions.\n",
        "\n",
        "\n",
        "    for epoch in range(1, 171):\n",
        "        loss = train()\n",
        "        acc = test()\n",
        "        print(f'Epoch: {epoch:03d},  Acc: {loss:.4f}, Loss: {acc:.4f}')\n",
        "        wandb.log({\"acc\": acc, \"loss\": loss})\n"
      ],
      "metadata": {
        "id": "oTcPAZ5yLWwG"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "9NOQP4rh34ei"
      },
      "outputs": [],
      "source": [
        "def graphMainModel(dataset,  num_classes, num_node_features):\n",
        "  dataset = dataset_MNIST.shuffle()\n",
        "  train_dataset = dataset[:150]\n",
        "  test_dataset = dataset[150:]\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "  model = GCNGraphClassifier(dataset.num_node_features, hidden_dim=hidden_dim, output_dim=dataset.num_classes).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  graph_train_model(train_loader,test_loader,optimizer, criterion, model, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in [dataset_ENZYMES]:\n",
        "  print(dataset)\n",
        "  graphMainModel(dataset, dataset.num_classes, dataset.num_node_features)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W1uTXnay3khT",
        "outputId": "5cdd7304-2414-4dfe-8508-e2c4ccb5b1fb"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENZYMES(600)\n",
            "Epoch: 001,  Acc: 4.7002, Loss: 0.0994\n",
            "Epoch: 002,  Acc: 4.5566, Loss: 0.1134\n",
            "Epoch: 003,  Acc: 4.4442, Loss: 0.1124\n",
            "Epoch: 004,  Acc: 4.3469, Loss: 0.1124\n",
            "Epoch: 005,  Acc: 4.2095, Loss: 0.1127\n",
            "Epoch: 006,  Acc: 4.2140, Loss: 0.1145\n",
            "Epoch: 007,  Acc: 4.1633, Loss: 0.1312\n",
            "Epoch: 008,  Acc: 4.0490, Loss: 0.1894\n",
            "Epoch: 009,  Acc: 4.0440, Loss: 0.1360\n",
            "Epoch: 010,  Acc: 3.9950, Loss: 0.0994\n",
            "Epoch: 011,  Acc: 3.9086, Loss: 0.0994\n",
            "Epoch: 012,  Acc: 3.9330, Loss: 0.0994\n",
            "Epoch: 013,  Acc: 3.9244, Loss: 0.1023\n",
            "Epoch: 014,  Acc: 3.9468, Loss: 0.1041\n",
            "Epoch: 015,  Acc: 3.7816, Loss: 0.1018\n",
            "Epoch: 016,  Acc: 3.7704, Loss: 0.1007\n",
            "Epoch: 017,  Acc: 3.7589, Loss: 0.1004\n",
            "Epoch: 018,  Acc: 3.7904, Loss: 0.1006\n",
            "Epoch: 019,  Acc: 3.7124, Loss: 0.1015\n",
            "Epoch: 020,  Acc: 3.6731, Loss: 0.1024\n",
            "Epoch: 021,  Acc: 3.6492, Loss: 0.1031\n",
            "Epoch: 022,  Acc: 3.5786, Loss: 0.1034\n",
            "Epoch: 023,  Acc: 3.5437, Loss: 0.1038\n",
            "Epoch: 024,  Acc: 3.5859, Loss: 0.1041\n",
            "Epoch: 025,  Acc: 3.5339, Loss: 0.1042\n",
            "Epoch: 026,  Acc: 3.4732, Loss: 0.1041\n",
            "Epoch: 027,  Acc: 3.4467, Loss: 0.1042\n",
            "Epoch: 028,  Acc: 3.4722, Loss: 0.1039\n",
            "Epoch: 029,  Acc: 3.4008, Loss: 0.1046\n",
            "Epoch: 030,  Acc: 3.3801, Loss: 0.1052\n",
            "Epoch: 031,  Acc: 3.4315, Loss: 0.1063\n",
            "Epoch: 032,  Acc: 3.3491, Loss: 0.1078\n",
            "Epoch: 033,  Acc: 3.2960, Loss: 0.1109\n",
            "Epoch: 034,  Acc: 3.2469, Loss: 0.1132\n",
            "Epoch: 035,  Acc: 3.3672, Loss: 0.1149\n",
            "Epoch: 036,  Acc: 3.2196, Loss: 0.1150\n",
            "Epoch: 037,  Acc: 3.2059, Loss: 0.1166\n",
            "Epoch: 038,  Acc: 3.2279, Loss: 0.1199\n",
            "Epoch: 039,  Acc: 3.2222, Loss: 0.1250\n",
            "Epoch: 040,  Acc: 3.2792, Loss: 0.1301\n",
            "Epoch: 041,  Acc: 3.1468, Loss: 0.1436\n",
            "Epoch: 042,  Acc: 3.1896, Loss: 0.1641\n",
            "Epoch: 043,  Acc: 3.0690, Loss: 0.1684\n",
            "Epoch: 044,  Acc: 3.1703, Loss: 0.1679\n",
            "Epoch: 045,  Acc: 3.0571, Loss: 0.1663\n",
            "Epoch: 046,  Acc: 2.8861, Loss: 0.1755\n",
            "Epoch: 047,  Acc: 2.9309, Loss: 0.1907\n",
            "Epoch: 048,  Acc: 2.9867, Loss: 0.2032\n",
            "Epoch: 049,  Acc: 2.9743, Loss: 0.2065\n",
            "Epoch: 050,  Acc: 3.0342, Loss: 0.2067\n",
            "Epoch: 051,  Acc: 2.9042, Loss: 0.1918\n",
            "Epoch: 052,  Acc: 2.8922, Loss: 0.1842\n",
            "Epoch: 053,  Acc: 2.8226, Loss: 0.1842\n",
            "Epoch: 054,  Acc: 2.8074, Loss: 0.1959\n",
            "Epoch: 055,  Acc: 2.8832, Loss: 0.1952\n",
            "Epoch: 056,  Acc: 2.8063, Loss: 0.1860\n",
            "Epoch: 057,  Acc: 2.7750, Loss: 0.1961\n",
            "Epoch: 058,  Acc: 2.8106, Loss: 0.2139\n",
            "Epoch: 059,  Acc: 2.7807, Loss: 0.2116\n",
            "Epoch: 060,  Acc: 2.7658, Loss: 0.1998\n",
            "Epoch: 061,  Acc: 2.7474, Loss: 0.1905\n",
            "Epoch: 062,  Acc: 2.6722, Loss: 0.2130\n",
            "Epoch: 063,  Acc: 2.6419, Loss: 0.2104\n",
            "Epoch: 064,  Acc: 2.5840, Loss: 0.1839\n",
            "Epoch: 065,  Acc: 2.6798, Loss: 0.1627\n",
            "Epoch: 066,  Acc: 2.6678, Loss: 0.1786\n",
            "Epoch: 067,  Acc: 2.5279, Loss: 0.1993\n",
            "Epoch: 068,  Acc: 2.6110, Loss: 0.2028\n",
            "Epoch: 069,  Acc: 2.4295, Loss: 0.1981\n",
            "Epoch: 070,  Acc: 2.5415, Loss: 0.2156\n",
            "Epoch: 071,  Acc: 2.5280, Loss: 0.2290\n",
            "Epoch: 072,  Acc: 2.6113, Loss: 0.2409\n",
            "Epoch: 073,  Acc: 2.4225, Loss: 0.2546\n",
            "Epoch: 074,  Acc: 2.3964, Loss: 0.2611\n",
            "Epoch: 075,  Acc: 2.3416, Loss: 0.2639\n",
            "Epoch: 076,  Acc: 2.3533, Loss: 0.2567\n",
            "Epoch: 077,  Acc: 2.4508, Loss: 0.2611\n",
            "Epoch: 078,  Acc: 2.2901, Loss: 0.2667\n",
            "Epoch: 079,  Acc: 2.1401, Loss: 0.2492\n",
            "Epoch: 080,  Acc: 2.1950, Loss: 0.1955\n",
            "Epoch: 081,  Acc: 2.1869, Loss: 0.1783\n",
            "Epoch: 082,  Acc: 2.2100, Loss: 0.1882\n",
            "Epoch: 083,  Acc: 2.1539, Loss: 0.1765\n",
            "Epoch: 084,  Acc: 2.1518, Loss: 0.2005\n",
            "Epoch: 085,  Acc: 2.1895, Loss: 0.2214\n",
            "Epoch: 086,  Acc: 2.2082, Loss: 0.2355\n",
            "Epoch: 087,  Acc: 2.1395, Loss: 0.2735\n",
            "Epoch: 088,  Acc: 2.2480, Loss: 0.2407\n",
            "Epoch: 089,  Acc: 2.1912, Loss: 0.1888\n",
            "Epoch: 090,  Acc: 2.1454, Loss: 0.1784\n",
            "Epoch: 091,  Acc: 2.0629, Loss: 0.1764\n",
            "Epoch: 092,  Acc: 2.0619, Loss: 0.1805\n",
            "Epoch: 093,  Acc: 2.1122, Loss: 0.1656\n",
            "Epoch: 094,  Acc: 1.9035, Loss: 0.1234\n",
            "Epoch: 095,  Acc: 2.0562, Loss: 0.1138\n",
            "Epoch: 096,  Acc: 1.9945, Loss: 0.1380\n",
            "Epoch: 097,  Acc: 2.0972, Loss: 0.1696\n",
            "Epoch: 098,  Acc: 1.9340, Loss: 0.1735\n",
            "Epoch: 099,  Acc: 1.9890, Loss: 0.1798\n",
            "Epoch: 100,  Acc: 1.9871, Loss: 0.1826\n",
            "Epoch: 101,  Acc: 1.9193, Loss: 0.1498\n",
            "Epoch: 102,  Acc: 2.0069, Loss: 0.1738\n",
            "Epoch: 103,  Acc: 1.9375, Loss: 0.1884\n",
            "Epoch: 104,  Acc: 1.9060, Loss: 0.1548\n",
            "Epoch: 105,  Acc: 1.8528, Loss: 0.1509\n",
            "Epoch: 106,  Acc: 1.7773, Loss: 0.1402\n",
            "Epoch: 107,  Acc: 1.8118, Loss: 0.1482\n",
            "Epoch: 108,  Acc: 1.9412, Loss: 0.1618\n",
            "Epoch: 109,  Acc: 1.7201, Loss: 0.2124\n",
            "Epoch: 110,  Acc: 1.7899, Loss: 0.2294\n",
            "Epoch: 111,  Acc: 1.6316, Loss: 0.2158\n",
            "Epoch: 112,  Acc: 1.6528, Loss: 0.1684\n",
            "Epoch: 113,  Acc: 1.6452, Loss: 0.1524\n",
            "Epoch: 114,  Acc: 1.7374, Loss: 0.1759\n",
            "Epoch: 115,  Acc: 1.6443, Loss: 0.1857\n",
            "Epoch: 116,  Acc: 1.4787, Loss: 0.2169\n",
            "Epoch: 117,  Acc: 1.6556, Loss: 0.2725\n",
            "Epoch: 118,  Acc: 1.6118, Loss: 0.2741\n",
            "Epoch: 119,  Acc: 1.6798, Loss: 0.2839\n",
            "Epoch: 120,  Acc: 1.5298, Loss: 0.3093\n",
            "Epoch: 121,  Acc: 1.6399, Loss: 0.2796\n",
            "Epoch: 122,  Acc: 1.4657, Loss: 0.2550\n",
            "Epoch: 123,  Acc: 1.5458, Loss: 0.3218\n",
            "Epoch: 124,  Acc: 1.5391, Loss: 0.3296\n",
            "Epoch: 125,  Acc: 1.6092, Loss: 0.3057\n",
            "Epoch: 126,  Acc: 1.5592, Loss: 0.3127\n",
            "Epoch: 127,  Acc: 1.7010, Loss: 0.2712\n",
            "Epoch: 128,  Acc: 1.4663, Loss: 0.2244\n",
            "Epoch: 129,  Acc: 1.4618, Loss: 0.2199\n",
            "Epoch: 130,  Acc: 1.4582, Loss: 0.2473\n",
            "Epoch: 131,  Acc: 1.3786, Loss: 0.2727\n",
            "Epoch: 132,  Acc: 1.5582, Loss: 0.2547\n",
            "Epoch: 133,  Acc: 1.3750, Loss: 0.2545\n",
            "Epoch: 134,  Acc: 1.5272, Loss: 0.2550\n",
            "Epoch: 135,  Acc: 1.3297, Loss: 0.2583\n",
            "Epoch: 136,  Acc: 1.3869, Loss: 0.2319\n",
            "Epoch: 137,  Acc: 1.4002, Loss: 0.2091\n",
            "Epoch: 138,  Acc: 1.3031, Loss: 0.2035\n",
            "Epoch: 139,  Acc: 1.2953, Loss: 0.1975\n",
            "Epoch: 140,  Acc: 1.2206, Loss: 0.1936\n",
            "Epoch: 141,  Acc: 1.2722, Loss: 0.2022\n",
            "Epoch: 142,  Acc: 1.2552, Loss: 0.2132\n",
            "Epoch: 143,  Acc: 1.4004, Loss: 0.1986\n",
            "Epoch: 144,  Acc: 1.1894, Loss: 0.1776\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-ab0c202fe79e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset_ENZYMES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mgraphMainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-f58ad662ee7a>\u001b[0m in \u001b[0;36mgraphMainModel\u001b[0;34m(dataset, num_classes, num_node_features)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mgraph_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-83-1de7e87b01b4>\u001b[0m in \u001b[0;36mgraph_train_model\u001b[0;34m(train_loader, test_loader, optimizer, criterion, model, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m171\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch:03d},  Acc: {loss:.4f}, Loss: {acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-1de7e87b01b4>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Iterate in batches over the training/test dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use the class with highest probability.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Check against ground-truth labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-cf97342cfd7c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         edge_index, edge_weight = add_remaining_self_loops(\n\u001b[0m\u001b[1;32m    100\u001b[0m             edge_index, edge_weight, fill_value, num_nodes)\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdgeIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_undirected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_undirected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mis_scripting\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m     r\"\"\"\n\u001b[1;32m   1132\u001b[0m     \u001b[0mFunction\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompilation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "8l-0d9l0J0FA",
        "outputId": "63394782-128f-4fb4-d2df-38dcfd39e20e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▁▁▁▃▃▄▄▄▄▄▃▄▄▆▆▆▄▃▅▅▆▃▃▂▃▄▃▃▄▃▄▇█▆▆▄▄▃</td></tr><tr><td>loss</td><td>███▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.17758</td></tr><tr><td>loss</td><td>1.18941</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dazzling-victory-4</strong> at: <a href='https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project/runs/8gljqey3' target=\"_blank\">https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project/runs/8gljqey3</a><br/> View project at: <a href='https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project' target=\"_blank\">https://wandb.ai/0322sagibenedek-budapesti-m-szaki-s-gazdas-gtudom-nyi-eg/GNN_project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241101_220332-8gljqey3/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUxv5CwDaffr"
      },
      "source": [
        "## 2.fázis\n",
        "--------\n",
        "Folytatás\n",
        "--------\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iUJzhbdCdSjQ",
        "G7t2n8qOJy8L",
        "Q3K5xViRWE72"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}